{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      6\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((28, 28)),\n",
    "    torchvision.transforms.Grayscale(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0,), (1,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('datasets', train=True, transform=transform, target_transform=None, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('datasets', train=False, transform=transform, target_transform=None, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Block\n",
    "\n",
    "In the original paper [ref] of the RestNet the residual blocks are comprised of two back-to-back convolutional (conv) layers, with a residual connection from the input of the first conv layer to the output of the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.shortcut_cupling = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut_cupling = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.shortcut_cupling:\n",
    "            identity = self.shortcut_cupling(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.res_blk1 = nn.Sequential(\n",
    "            ResidualBlock(64, 64, stride=1),\n",
    "            ResidualBlock(64, 64, stride=1),\n",
    "            ResidualBlock(64, 64, stride=1)\n",
    "        )\n",
    "\n",
    "        self.res_blk2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, stride=1),\n",
    "            ResidualBlock(128, 128, stride=1),\n",
    "            ResidualBlock(128, 128, stride=1),\n",
    "            ResidualBlock(128, 128, stride=1)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.res_blk1(out)\n",
    "        out = self.res_blk2(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_testloader():\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "\n",
    "        for data, labels in iter(test_loader):\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            out = model(data)\n",
    "\n",
    "            _, predictions = torch.max(out.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            del data, labels, out\n",
    "\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (522423788.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    test_accuracies.append(test_acc*100:.4f)\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "bc = 0\n",
    "batches = []\n",
    "test_accuracies = []\n",
    "\n",
    "for data, labels in iter(train_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    preds = model(data)\n",
    "\n",
    "    loss = loss_fn(preds, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    bc += 1\n",
    "\n",
    "    del data, labels, preds\n",
    "\n",
    "    torch.cuda.empty_cache()                        #  releases the cache held by the CUDA memory allocator\n",
    "\n",
    "    test_acc = run_on_testloader()\n",
    "\n",
    "    print(f'batch {bc}, training loss: {loss.item():.4f}, test accuracy: {test_acc*100:.4f}\\%')\n",
    "\n",
    "    batches.append(bc)\n",
    "    test_accuracies.append(test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batches, test_accuracies, '-o')\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('test accuracy (%)')\n",
    "plt.xlabel('training batch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
